found flag keys_file = ../test_data_used_in_paper/binom-200M.bin.data
found flag keys_file_type = binary
found flag init_num_keys = 10000000
found flag total_num_keys = 110000000
found flag batch_size = 2000
found flag insert_frac = 0.05
found flag lookup_distribution = zipf
Loading keys from file...
[Loading keys from file] Done.
workload start.
Cumulative stats: 50001 batches, 100000000 ops (95000000 lookups, 5000000 inserts)
	cumulative throughput:	9.928e+06 lookups/sec,	2.992e+06 inserts/sec,	8.897e+06 ops/sec
STATS:
num_keys: 15000000
num_model_nodes: 4419
num_data_nodes: 53481
num_expand_and_scales: 384
num_expand_and_retrains: 308
num_downward_splits: 0
num_sideways_splits: 489
num_downward_split_keys: 0
num_model_node_expansion_pointers: 76008
num_model_node_split_pointers: 0
num_node_lookups: 208761732
num_lookups: 95000000
num_inserts: 5000000
splitting_time: 3.010e+07
cost_computation_time: 1.299e+06

Data_Node_Size_avg: 6.372e+03
Total size: 3.265e+02MB
Avg level: 2.200e+00
Max level: 4
Max model node size: 524352B
Max data node size: 16329856B
Total exp-search iterations: 290158619
Total shifts: 103009795
