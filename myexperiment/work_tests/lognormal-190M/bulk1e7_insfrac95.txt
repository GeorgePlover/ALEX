found flag keys_file = ../test_data_used_in_paper/lognormal-190M.bin.data
found flag keys_file_type = binary
found flag init_num_keys = 10000000
found flag total_num_keys = 110000000
found flag batch_size = 2000
found flag insert_frac = 0.95
found flag lookup_distribution = zipf
Loading keys from file...
[Loading keys from file] Done.
workload start.
Cumulative stats: 50001 batches, 100000000 ops (5000000 lookups, 95000000 inserts)
	cumulative throughput:	1.722e+07 lookups/sec,	4.599e+06 inserts/sec,	4.774e+06 ops/sec
STATS:
num_keys: 105000000
num_model_nodes: 12
num_data_nodes: 1180
num_expand_and_scales: 426
num_expand_and_retrains: 65
num_downward_splits: 1
num_sideways_splits: 37
num_downward_split_keys: 497671
num_model_node_expansion_pointers: 1572992
num_model_node_split_pointers: 0
num_node_lookups: 141457202
num_lookups: 5000000
num_inserts: 95000000
splitting_time: 4.804e+08
cost_computation_time: 2.288e+08

Data_Node_Size_avg: 1.966e+06
Total size: 2.226e+03MB
Avg level: 1.193e+00
Max level: 3
Max model node size: 16777280B
Max data node size: 16729064B
Total exp-search iterations: 52092238
Total shifts: 563906402
