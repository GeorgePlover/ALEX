found flag keys_file = ../test_data_used_in_paper/lognormal-190M.bin.data
found flag keys_file_type = binary
found flag init_num_keys = 10000000
found flag total_num_keys = 190000000
found flag batch_size = 2000
found flag insert_frac = 0.75
found flag lookup_distribution = zipf
found flag time_limit = 1
Loading keys from file...
[Loading keys from file] Done.
workload start.
Cumulative stats: 120001 batches, 240000500 ops (60000500 lookups, 180000000 inserts)
	cumulative throughput:	2.043e+07 lookups/sec,	4.563e+06 inserts/sec,	5.663e+06 ops/sec
STATS:
num_keys: 190000000
num_model_nodes: 51
num_data_nodes: 1056
num_expand_and_scales: 1041
num_expand_and_retrains: 40
num_downward_splits: 43
num_sideways_splits: 176
num_downward_split_keys: 22964079
num_model_node_expansion_pointers: 1573372
num_model_node_split_pointers: 0
num_node_lookups: 343278559
num_lookups: 60000500
num_inserts: 180000000
splitting_time: 2.105e+09
cost_computation_time: 5.793e+08

Total size: 5.296e+03MB
Max level: 2
Max model node size: 16777280B
Max data node size: 16907856B
Total exp-search iterations: 75329090
Total shifts: 282389935
