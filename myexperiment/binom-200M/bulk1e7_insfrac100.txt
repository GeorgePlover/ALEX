found flag keys_file = ../test_data_used_in_paper/binom-200M.bin.data
found flag keys_file_type = binary
found flag init_num_keys = 10000000
found flag total_num_keys = 200000000
found flag batch_size = 2000
found flag insert_frac = 1.00
found flag lookup_distribution = zipf
found flag time_limit = 1
Loading keys from file...
[Loading keys from file] Done.
workload start.
Cumulative stats: 95001 batches, 190000000 ops (0 lookups, 190000000 inserts)
	cumulative throughput:	0.000e+00 lookups/sec,	8.918e+06 inserts/sec,	8.917e+06 ops/sec
STATS:
num_keys: 200000000
num_model_nodes: 22785
num_data_nodes: 277690
num_expand_and_scales: 829159
num_expand_and_retrains: 899400
num_downward_splits: 17975
num_sideways_splits: 190388
num_downward_split_keys: 7551839
num_model_node_expansion_pointers: 2176482
num_model_node_split_pointers: 0
num_node_lookups: 193587004
num_lookups: 0
num_inserts: 190000000
splitting_time: 9.572e+09
cost_computation_time: 4.080e+09

Total size: 5.823e+03MB
Max level: 6
Max model node size: 16777280B
Max data node size: 5480016B
Total exp-search iterations: 493485760
Total shifts: 541298408
